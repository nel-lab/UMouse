#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Thu May 27 12:02:56 2021

@author: andreagiovannucci
"""
import numpy as np
import pandas as pd
from behavelet import wavelet_transform
import umap
import os
#%%
class UMouse:
    def __init__(self, n_frequencies=25, f_sample=70, fmin=1, fmax=None, n_neighbors=15, n_components=2,**kwargs): 
        """
        
        Parameters
        ----------
        n_frequencies : int
            number of groups to divide the frequencies range into.
        fsample : int
            sampling frequency
        fmin : float
            minimum frequency of interest for the wavelet transformation.
        fmax : float
            maximum frequency of interest for the wavelet transformation.
        n_neighbors: int 
            see UMAP doc
        n_components: int
            see UMAP doc
        **kwargs : Misc
            keyword arguments for the UMAP class object initialization

        Returns
        -------
        None.

        """
        
        # default to Nyquist frequency
        if fmax is None:
            fmax = 0.5*f_sample
    
        self.n_frequencies=n_frequencies
        self.f_sample=f_sample
        self.fmin=fmin
        self.fmax=fmax       
        
        self.n_neighbors = n_neighbors
        self.n_components = n_components
        
        self.fit_data = None
        self.UMAP = umap.UMAP(n_neighbors=n_neighbors, n_components=n_components,**kwargs) 
        #   fr_per_sess : integer, optional
        # Number of frames to sample from each dataset. Only used if multiple datasets are indicated in fit_path. 
        # The default is 50000/(n datasets).  

    def fit(self, df, fr_per_sess=5000, columns=None, recompute_mwt=False, trim_mov=None):
        """
        Loads frames to generate the embedding fit and performs the fit. Stores model as a class field. It assumes that auxiliary files are  created
        when computing the wavelet transform. If you want to recompute the transform 

        Parameters
        ----------
        df: dataframe,  a path or list of paths
            Df, Path or list of both for the behavioral data to be analyzed. The input format is compatible with DLC output

        fr_per_sess: int
            number of frames to be used per session, if less than 0 all frames in all sessions are used
            
        columns: list of strings
            in case only a subset of the columns need to be used
        
        recompute_mwt: Boolean
            if you want to recompute the MWT. You can also erase the  auxiliary xxx_mwt.npy files
            
        trim_mov: int
            Only extracts frames from the first trim_mov number of frames. Default is None.

        Returns
        -------
        class field object of the umap object with a fit model

        """
        if (type(df) is not list) or (not os.path.exists(df[0])):
            raise Exception('The input must be a list of paths to existing csv files')
    
        
        for ddf in df:
             fit_data = []
             target_path = ddf.split('.')[0]+'_mwt.npy'
             if os.path.exists(target_path) and not recompute_mwt:
                print('Found file: ' + target_path + ", not recomputing wavelet transform")
                try:
                    spect_data = np.load(target_path)
                except:
                    spect_data = pd.read_csv(target_path)
             else:
                print('computing morlet wavelet transform')
                if columns is not None:
                    df_one_mouse = pd.read_csv(ddf, usecols=columns)
                else:
                    df_one_mouse = pd.read_csv(ddf)
                freqs, power, spect_data = self._compute_mwt(df_one_mouse, self.n_frequencies, self.f_sample, self.fmin, self.fmax)
                np.save(target_path, spect_data) 
            
             if (fr_per_sess is None) or (fr_per_sess < 0):
                fit_data.append(spect_data)
             elif (fr_per_sess > 0) and (trim_mov is not None):
                fit_data.append(spect_data[:-1][::trim_mov//fr_per_sess])
             else:
                fit_data.append(spect_data[:-1][::len(spect_data)//fr_per_sess]) # select only fr_per_sess per mouse
        
        fit_data = np.vstack(fit_data)

        print('initiating UMAP fit')
        self.UMAP.fit(fit_data)
              
            
    def transform(self, transform_path, run_id=None):
        """
        Uses the embedding model generated by self.fit to transform the datasets indicated. 

        Parameters
        ----------
        transform_path : list
            Path or list of paths for the spectrographic data to be analyzed. 
        run_id : list of strings
            unique tag to apply to each run. Use if saving different model embeddings

        Returns
        -------
        None.

        """
        if (type(transform_path) is not list) or (not os.path.exists(transform_path[0])):
            raise Exception('The input must be a list of paths to existing csv files')
            
        for this_path in transform_path:
            if run_id is not None:
                output_suffix = run_id + '_umap.csv'
                
            if this_path.endswith('_mwt.npy'):
                target_path = this_path
                output_path_csv = this_path.split('_mwt')[0] + output_suffix
            else:
                target_path = this_path.split('.')[0]+'_mwt.npy'
                output_path_csv = this_path.split('.')[0] + output_suffix
                
            if os.path.exists(target_path):
               print('Found file: ' + target_path)
               spect_data = np.load(target_path)
               
               #transform the new dataset
               print('file loaded, embedding data. This may take a few minutes.')
               this_embedding = self.UMAP.transform(spect_data)
               this_embedding = pd.DataFrame(this_embedding, columns=['dim_' + str(i) for i in range(this_embedding.shape[1])])
               
               #save the new embedding
               print('transform complete, saving data')
               this_embedding.to_csv(output_path_csv)
               
            else:  
               raise Exception('File '+target_path+' not found,' + "Be sure you run the fit method first")
    
        

    def _compute_mwt(self, behavior_df, n_frequencies, f_sample, fmin, fmax):
        """
        Perform morlet wavelett transformation on the DLC data

        Parameters
        ----------
        behavior_df : pandas dataframe
            dataframe containing the DLC trajectory data.
        n_frequencies : int
            number of groups to divide the frequencies range into.
        fsample : int
            sampling frequency
        fmin : float
            minimum frequency of interest for the wavelet transformation.
        fmax : float
            maximum frequency of interest for the wavelet transformation.

        Returns
        -------
        freqs : ndarray, shape (n_freqs)
            The frequencies used for the wavelet transform
        power : ndarray, shape (n_samples)
            The total power for each row in X_new
        mwt_array : numpy array, shape (n_samples, n_features*n_freqs)
            Continuous wavelet transformed data

        """
        
        #perform transformation
        freqs, power, mwt_array = wavelet_transform(behavior_df.to_numpy(), 
                                                    n_freqs=n_frequencies, 
                                                    fsample=f_sample, 
                                                    fmin=fmin, 
                                                    fmax=fmax)
        
        return freqs, power, mwt_array
